{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>search term</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>New #knife post on our forum! » New Opinel #6 ...</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>mtjsblog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>new knife post forum new opinel httpstcoprbmwh...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>New #shtf discussion on our forum! » https://t...</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>mtjsblog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>new shtf discussion forum httpstcowzretpdwb</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Good time this weekend with our @twistedtea @c...</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>tydillon</td>\n",
       "      <td>Welcome, North Carolina</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>good time weekend twistedtea chevy texas call_...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Proud of GEICO’s dedication to NASCAR! https:/...</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>tydillon</td>\n",
       "      <td>Welcome, North Carolina</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>proud geico dedication nascar httpstcouqxaszkrv</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Summer is in the air! Call us to get started o...</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>JSQimprovements</td>\n",
       "      <td>Huntington Beach, CA</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>summer air call us get started custom swimming...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text        Date  \\\n",
       "0  New #knife post on our forum! » New Opinel #6 ...  2019-03-24   \n",
       "1  New #shtf discussion on our forum! » https://t...  2019-03-18   \n",
       "2  Good time this weekend with our @twistedtea @c...  2019-04-01   \n",
       "3  Proud of GEICO’s dedication to NASCAR! https:/...  2019-03-25   \n",
       "4  Summer is in the air! Call us to get started o...  2019-04-10   \n",
       "\n",
       "              Name                 Location search term  \\\n",
       "0         mtjsblog                      NaN     outdoor   \n",
       "1         mtjsblog                      NaN     outdoor   \n",
       "2         tydillon  Welcome, North Carolina     outdoor   \n",
       "3         tydillon  Welcome, North Carolina     outdoor   \n",
       "4  JSQimprovements     Huntington Beach, CA     outdoor   \n",
       "\n",
       "                                          clean_text    type  \n",
       "0  new knife post forum new opinel httpstcoprbmwh...  active  \n",
       "1        new shtf discussion forum httpstcowzretpdwb  active  \n",
       "2  good time weekend twistedtea chevy texas call_...  active  \n",
       "3    proud geico dedication nascar httpstcouqxaszkrv  active  \n",
       "4  summer air call us get started custom swimming...  active  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active = pd.read_csv(\"active19-clean.csv\", \n",
    "                     usecols=['Text','Date','Name','Location','search term','clean_text'])\n",
    "active20 = pd.read_csv(\"active20-clean.csv\", \n",
    "                     usecols=['Text','Date','Name','Location','search term','clean_text'])\n",
    "active = active.append(active20)\n",
    "active['type'] = 'active'\n",
    "active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy = pd.read_csv(\"lazy19-clean.csv\", \n",
    "                     usecols=['Text','Date','Name','Location','search term','clean_text'])\n",
    "lazy20 = pd.read_csv(\"lazy20-clean.csv\", \n",
    "                     usecols=['Text','Date','Name','Location','search term','clean_text'])\n",
    "lazy = lazy.append(lazy20)\n",
    "lazy['type']='lazy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = active.append(lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>search term</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>New #knife post on our forum! » New Opinel #6 ...</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>mtjsblog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>new knife post forum new opinel httpstcoprbmwh...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>New #shtf discussion on our forum! » https://t...</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>mtjsblog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>new shtf discussion forum httpstcowzretpdwb</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Good time this weekend with our @twistedtea @c...</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>tydillon</td>\n",
       "      <td>Welcome, North Carolina</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>good time weekend twistedtea chevy texas call_...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Proud of GEICO’s dedication to NASCAR! https:/...</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>tydillon</td>\n",
       "      <td>Welcome, North Carolina</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>proud geico dedication nascar httpstcouqxaszkrv</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Summer is in the air! Call us to get started o...</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>JSQimprovements</td>\n",
       "      <td>Huntington Beach, CA</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>summer air call us get started custom swimming...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text        Date  \\\n",
       "0  New #knife post on our forum! » New Opinel #6 ...  2019-03-24   \n",
       "1  New #shtf discussion on our forum! » https://t...  2019-03-18   \n",
       "2  Good time this weekend with our @twistedtea @c...  2019-04-01   \n",
       "3  Proud of GEICO’s dedication to NASCAR! https:/...  2019-03-25   \n",
       "4  Summer is in the air! Call us to get started o...  2019-04-10   \n",
       "\n",
       "              Name                 Location search term  \\\n",
       "0         mtjsblog                      NaN     outdoor   \n",
       "1         mtjsblog                      NaN     outdoor   \n",
       "2         tydillon  Welcome, North Carolina     outdoor   \n",
       "3         tydillon  Welcome, North Carolina     outdoor   \n",
       "4  JSQimprovements     Huntington Beach, CA     outdoor   \n",
       "\n",
       "                                          clean_text    type  \n",
       "0  new knife post forum new opinel httpstcoprbmwh...  active  \n",
       "1        new shtf discussion forum httpstcowzretpdwb  active  \n",
       "2  good time weekend twistedtea chevy texas call_...  active  \n",
       "3    proud geico dedication nascar httpstcouqxaszkrv  active  \n",
       "4  summer air call us get started custom swimming...  active  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to build a prediction of whether the user is active or lazy based on the words used for active and lazy users. We will use a Naive Bayes Multinomial Model to predict the type of the user. We want to predict a category with labelled data and over 100K samples of text data, so it is appropriate to use Naive Bayes as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store tweet dataset into feature matrix and response vector\n",
    "X_words = df['clean_text']\n",
    "y_words = df['type']\n",
    "\n",
    "# Instantiate CountVectorizer and TfidfVectorizer\n",
    "count_vect = CountVectorizer(min_df=1, ngram_range=(1, 2)) \n",
    "tfidf_vect = TfidfVectorizer(min_df=1, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "# Apply CountVectorizer \n",
    "X_count = count_vect.fit_transform(df['clean_text'].apply(str))\n",
    "X_count = X_count.tocsc() \n",
    "\n",
    "# Apply TfidfVectorizer\n",
    "X_tfidf = tfidf_vect.fit_transform(df['clean_text'].apply(str))\n",
    "X_tfidf = X_tfidf.tocsc()\n",
    "\n",
    "\n",
    "# Split train/test data for all data\n",
    "Xtrain_count, Xtest_count, ytrain_count, ytest_count = train_test_split(X_count, y_words, random_state=17)\n",
    "Xtrain_tfidf, Xtest_tfidf, ytrain_tfidf, ytest_tfidf = train_test_split(X_tfidf, y_words, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(xtest, ytest, clf):\n",
    "    \"\"\" \n",
    "    This function evaluates the effectiveness of a ML model and outputs F1 Scores, AUC score and Confusion Matrix\n",
    "    \"\"\"\n",
    "    # Make predictions for Xtest\n",
    "    y_pred = clf.predict(xtest)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = metrics.confusion_matrix(ytest, y_pred)\n",
    "    \n",
    "    print(classification_report(ytest, y_pred))\n",
    "    print('\\nConfusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate multinomialNB()\n",
    "nb_words_count = MultinomialNB(alpha=1, fit_prior=True)\n",
    "nb_words_tfidf = MultinomialNB(alpha=1, fit_prior=True)\n",
    "\n",
    "# Train model\n",
    "nb_words_count.fit(Xtrain_count, ytrain_count)\n",
    "nb_words_tfidf.fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      active       0.83      0.71      0.77     15523\n",
      "        lazy       0.70      0.82      0.76     12657\n",
      "\n",
      "    accuracy                           0.76     28180\n",
      "   macro avg       0.76      0.77      0.76     28180\n",
      "weighted avg       0.77      0.76      0.76     28180\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11080  4443]\n",
      " [ 2285 10372]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, nb_words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1-score is 77%. The number of False Positives (2,285) is low compared to True Positives (11,080). True Negatives number (10,372) is also much higher than False Negatives (4,443)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      active       0.71      0.90      0.79     15523\n",
      "        lazy       0.81      0.54      0.65     12657\n",
      "\n",
      "    accuracy                           0.74     28180\n",
      "   macro avg       0.76      0.72      0.72     28180\n",
      "weighted avg       0.75      0.74      0.73     28180\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13911  1612]\n",
      " [ 5789  6868]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, nb_words_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-1 score is 77%. The proportion for False Positives to True Positives and False Negatives to True Negatives stay around the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we can conclude that the model is good, but we will try to tune in the hyperparameter alpha to make the predictions even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': (1,0.1,0.01,0.001,2,5,10,25)} \n",
    "\n",
    "multinom_cv = GridSearchCV(nb_words_count, param_grid, cv=5, scoring='roc_auc') \n",
    "multinom_cv.fit(Xtrain_count, ytrain_count) \n",
    "multinom_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421094523447299"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinom_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': (1,0.1,0.01,0.001,2,5,10,25)} \n",
    "\n",
    "tdidf_multinom_cv = GridSearchCV(nb_words_tfidf, param_grid, cv=5, scoring='roc_auc') \n",
    "tdidf_multinom_cv.fit(Xtrain_tfidf, ytrain_tfidf) \n",
    "tdidf_multinom_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8480343803693777"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdidf_multinom_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC-AUC score has improved to 84% for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review top 20 most important words for predicting the active users on twitter by using sklearn feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a291829bb69b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnb_words_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mzipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_words_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "nb_words_count = \n",
    "nb_words_count.fit(Xtest_count, ytest_count) \n",
    "zipped = zip(df.clean_text,nb_words_count.feature_importances_)\n",
    "res = sorted(zipped, key = lambda x: x[1], reverse=True)\n",
    "_ = plt.figure(figsize=(20,10))\n",
    "for i in res[0:20]:\n",
    "    _ = plt.bar(i[0],i[1], color='blue')\n",
    "    _ = plt.title('Top 20 Most Important Words to Predict Active Users on Twitter')\n",
    "    _ = plt.xlabel('Features')\n",
    "    _ = plt.xticks(rotation=45)\n",
    "    _ = plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_optimal = MultinomialNB(alpha=1, fit_prior=True)\n",
    "NBtdidf_optimal = MultinomialNB(alpha=0.1, fit_prior=True)\n",
    "\n",
    "#neg_class_prob_sorted = NB_optimal.coef_[0, :]\n",
    "#pos_class_prob_sorted = NB_optimal.coef_[1, :].argsort()\n",
    "\n",
    "#print(np.take(count_vect.get_feature_names(), neg_class_prob_sorted[:10]))\n",
    "#print(np.take(count_vect.get_feature_names(), pos_class_prob_sorted[:10]))\n",
    "\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3fd6caa17f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNB_optimal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-20943e0457d9>\u001b[0m in \u001b[0;36mshow_most_informative_features\u001b[1;34m(vectorizer, clf, n)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mcoefs_with_fns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefs_with_fns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoefs_with_fns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcoef_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcoef_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_get_coef\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_coef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         return (self.feature_log_prob_[1:]\n\u001b[1;32m--> 623\u001b[1;33m                 if len(self.classes_) == 2 else self.feature_log_prob_)\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_intercept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(count_vect, NB_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
